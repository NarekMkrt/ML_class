{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large scale text analysis with deep learning\n",
    "\n",
    "Today we're gonna apply the newly learned tools for the task of predicting job salary.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3342/media/salary%20prediction%20engine%20v2.png\" width=400px>\n",
    "\n",
    "_Special thanks to [Oleg Vasilev](https://github.com/Omrigan/) for the core assignment idea._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the challenge\n",
    "For starters, let's download and unpack the data from [here](https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=0). \n",
    "\n",
    "You can also get it from [yadisk url](https://yadi.sk/d/vVEOWPFY3NruT7) the competition [page](https://www.kaggle.com/c/job-salary-prediction/data) (pick `Train_rev1.*`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    17    0    17    0     0     23      0 --:--:-- --:--:-- --:--:--    23\n",
      "\n",
      "100   299  100   299    0     0    214      0  0:00:01  0:00:01 --:--:--   214\n",
      "100   299  100   299    0     0    214      0  0:00:01  0:00:01 --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "  0  119M    0  480k    0     0   156k      0  0:13:04  0:00:03  0:13:01  879k\n",
      "  1  119M    1 1648k    0     0   404k      0  0:05:02  0:00:04  0:04:58 1069k\n",
      "  1  119M    1 2240k    0     0   429k      0  0:04:45  0:00:05  0:04:40  835k\n",
      "  2  119M    2 3120k    0     0   513k      0  0:03:58  0:00:06  0:03:52  880k\n",
      "  2  119M    2 3664k    0     0   517k      0  0:03:56  0:00:07  0:03:49  805k\n",
      "  3  119M    3 4464k    0     0   533k      0  0:03:49  0:00:08  0:03:41  753k\n",
      "  4  119M    4 5152k    0     0   567k      0  0:03:35  0:00:09  0:03:26  700k\n",
      "  4  119M    4 5760k    0     0   571k      0  0:03:34  0:00:10  0:03:24  724k\n",
      "  5  119M    5 6896k    0     0   622k      0  0:03:16  0:00:11  0:03:05  755k\n",
      "  6  119M    6 7888k    0     0   647k      0  0:03:09  0:00:12  0:02:57  826k\n",
      "  7  119M    7 8896k    0     0   677k      0  0:03:00  0:00:13  0:02:47  930k\n",
      "  8  119M    8 10.1M    0     0   736k      0  0:02:46  0:00:14  0:02:32 1043k\n",
      "  9  119M    9 11.0M    0     0   741k      0  0:02:45  0:00:15  0:02:30 1075k\n",
      "  9  119M    9 11.5M    0     0   732k      0  0:02:47  0:00:16  0:02:31  968k\n",
      " 10  119M   10 12.9M    0     0   776k      0  0:02:37  0:00:17  0:02:20 1100k\n",
      " 12  119M   12 14.5M    0     0   825k      0  0:02:28  0:00:18  0:02:10 1215k\n",
      " 14  119M   14 16.8M    0     0   904k      0  0:02:15  0:00:19  0:01:56 1376k\n",
      " 15  119M   15 18.0M    0     0   919k      0  0:02:13  0:00:20  0:01:53 1467k\n",
      " 16  119M   16 19.7M    0     0   960k      0  0:02:07  0:00:21  0:01:46 1719k\n",
      " 18  119M   18 21.8M    0     0  1013k      0  0:02:00  0:00:22  0:01:38 1821k\n",
      " 19  119M   19 22.7M    0     0  1006k      0  0:02:01  0:00:23  0:01:38 1643k\n",
      " 20  119M   20 25.0M    0     0  1051k      0  0:01:56  0:00:24  0:01:32 1581k\n",
      " 21  119M   21 25.6M    0     0  1032k      0  0:01:58  0:00:25  0:01:33 1466k\n",
      " 22  119M   22 26.7M    0     0  1051k      0  0:01:56  0:00:26  0:01:30 1432k\n",
      " 23  119M   23 28.6M    0     0  1082k      0  0:01:53  0:00:27  0:01:26 1387k\n",
      " 25  119M   25 30.0M    0     0  1097k      0  0:01:51  0:00:28  0:01:23 1531k\n",
      " 26  119M   26 31.2M    0     0  1101k      0  0:01:51  0:00:29  0:01:22 1360k\n",
      " 26  119M   26 31.8M    0     0  1081k      0  0:01:53  0:00:30  0:01:23 1336k\n",
      " 27  119M   27 32.7M    0     0  1079k      0  0:01:53  0:00:31  0:01:22 1224k\n",
      " 28  119M   28 33.5M    0     0  1069k      0  0:01:54  0:00:32  0:01:22  998k\n",
      " 28  119M   28 34.6M    0     0  1067k      0  0:01:54  0:00:33  0:01:21  902k\n",
      " 29  119M   29 35.2M    0     0  1057k      0  0:01:55  0:00:34  0:01:21  804k\n",
      " 30  119M   30 35.9M    0     0  1044k      0  0:01:57  0:00:35  0:01:22  824k\n",
      " 30  119M   30 36.6M    0     0  1034k      0  0:01:58  0:00:36  0:01:22  762k\n",
      " 31  119M   31 38.0M    0     0  1050k      0  0:01:56  0:00:37  0:01:19  926k\n",
      " 32  119M   32 39.1M    0     0  1052k      0  0:01:56  0:00:38  0:01:18  951k\n",
      " 32  119M   32 39.3M    0     0  1030k      0  0:01:58  0:00:39  0:01:19  842k\n",
      " 34  119M   34 40.8M    0     0  1040k      0  0:01:57  0:00:40  0:01:17 1012k\n",
      " 34  119M   34 41.2M    0     0  1026k      0  0:01:59  0:00:41  0:01:18  971k\n",
      " 34  119M   34 41.8M    0     0  1018k      0  0:02:00  0:00:42  0:01:18  780k\n",
      " 35  119M   35 42.7M    0     0  1016k      0  0:02:00  0:00:43  0:01:17  747k\n",
      " 36  119M   36 44.2M    0     0  1027k      0  0:01:59  0:00:44  0:01:15 1003k\n",
      " 38  119M   38 45.5M    0     0  1033k      0  0:01:58  0:00:45  0:01:13  977k\n",
      " 38  119M   38 46.6M    0     0  1036k      0  0:01:58  0:00:46  0:01:12 1113k\n",
      " 39  119M   39 47.2M    0     0  1027k      0  0:01:59  0:00:47  0:01:12 1100k\n",
      " 40  119M   40 48.5M    0     0  1033k      0  0:01:58  0:00:48  0:01:10 1179k\n",
      " 42  119M   42 50.2M    0     0  1048k      0  0:01:56  0:00:49  0:01:07 1241k\n",
      " 43  119M   43 52.5M    0     0  1074k      0  0:01:54  0:00:50  0:01:04 1442k\n",
      " 46  119M   46 55.3M    0     0  1109k      0  0:01:50  0:00:51  0:00:59 1788k\n",
      " 48  119M   48 58.4M    0     0  1149k      0  0:01:46  0:00:52  0:00:54 2308k\n",
      " 51  119M   51 61.4M    0     0  1184k      0  0:01:43  0:00:53  0:00:50 2635k\n",
      " 54  119M   54 65.0M    0     0  1230k      0  0:01:39  0:00:54  0:00:45 3018k\n",
      " 56  119M   56 67.3M    0     0  1252k      0  0:01:37  0:00:55  0:00:42 3032k\n",
      " 58  119M   58 70.0M    0     0  1279k      0  0:01:35  0:00:56  0:00:39 3017k\n",
      " 61  119M   61 73.6M    0     0  1321k      0  0:01:32  0:00:57  0:00:35 3111k\n",
      " 63  119M   63 76.3M    0     0  1346k      0  0:01:31  0:00:58  0:00:33 3057k\n",
      " 65  119M   65 78.8M    0     0  1365k      0  0:01:29  0:00:59  0:00:30 2815k\n",
      " 68  119M   68 81.3M    0     0  1387k      0  0:01:28  0:01:00  0:00:28 2876k\n",
      " 69  119M   69 83.7M    0     0  1403k      0  0:01:27  0:01:01  0:00:26 2789k\n",
      " 72  119M   72 87.0M    0     0  1436k      0  0:01:25  0:01:02  0:00:23 2754k\n",
      " 76  119M   76 91.0M    0     0  1477k      0  0:01:22  0:01:03  0:00:19 3008k\n",
      " 78  119M   78 93.8M    0     0  1499k      0  0:01:21  0:01:04  0:00:17 3078k\n",
      " 81  119M   81 96.9M    0     0  1525k      0  0:01:20  0:01:05  0:00:15 3187k\n",
      " 83  119M   83  100M    0     0  1549k      0  0:01:19  0:01:06  0:00:13 3329k\n",
      " 86  119M   86  103M    0     0  1586k      0  0:01:17  0:01:07  0:00:10 3453k\n",
      " 89  119M   89  106M    0     0  1608k      0  0:01:16  0:01:08  0:00:08 3260k\n",
      " 93  119M   93  112M    0     0  1665k      0  0:01:13  0:01:09  0:00:04 3803k\n",
      " 98  119M   98  118M    0     0  1728k      0  0:01:10  0:01:10 --:--:-- 4368k\n",
      "100  119M  100  119M    0     0  1738k      0  0:01:10  0:01:10 --:--:-- 4606k\n",
      "x Train_rev1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(244768, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!curl -L https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1 -o Train_rev1.csv.tar.gz\n",
    "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
    "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with salary prediction is that it's oddly distributed: there are many people who are paid standard salaries and a few that get tons o money. The distribution is fat-tailed on the right side, which is inconvenient for MSE minimization.\n",
    "\n",
    "There are several techniques to combat this: using a different loss function, predicting log-target instead of raw target or even replacing targets with their percentiles among all salaries in the training set. We gonna use logarithm for now.\n",
    "\n",
    "_You can read more [in the official description](https://www.kaggle.com/c/job-salary-prediction#description)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data[\"SalaryNormalized\"], bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data['Log1pSalary'], bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task is to predict one number, __Log1pSalary__.\n",
    "\n",
    "To do so, our model can access a number of features:\n",
    "* Free text: __`Title`__ and  __`FullDescription`__\n",
    "* Categorical: __`Category`__, __`Company`__, __`LocationNormalized`__, __`ContractType`__, and __`ContractTime`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>Log1pSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138048</th>\n",
       "      <td>70437077</td>\n",
       "      <td>WEB &amp; GRAPHIC DESIGNER</td>\n",
       "      <td>These are exciting times, with new clients com...</td>\n",
       "      <td>Buckinghamshire, England</td>\n",
       "      <td>Buckinghamshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR, Advertising &amp; Marketing Jobs</td>\n",
       "      <td>28000 - 30000 per annum + Benefits</td>\n",
       "      <td>29000</td>\n",
       "      <td>onlymarketingjobs.com</td>\n",
       "      <td>10.275085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227554</th>\n",
       "      <td>72444591</td>\n",
       "      <td>Product Specialist  Facial  Midlands</td>\n",
       "      <td>Product Specialist  Facial  Midlands Our clien...</td>\n",
       "      <td>West Midlands</td>\n",
       "      <td>West Midlands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Additional Resources Ltd</td>\n",
       "      <td>Sales Jobs</td>\n",
       "      <td>33000 Per Annum</td>\n",
       "      <td>33000</td>\n",
       "      <td>totaljobs.com</td>\n",
       "      <td>10.404293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10252</th>\n",
       "      <td>66314930</td>\n",
       "      <td>Commercial Lending Manager</td>\n",
       "      <td>COMMERCIAL LENDING MANAGER This is an exciting...</td>\n",
       "      <td>Cheadle</td>\n",
       "      <td>Cheadle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blemain Finance</td>\n",
       "      <td>Accounting &amp; Finance Jobs</td>\n",
       "      <td>up to 70,000 plus bonus, car and benefits</td>\n",
       "      <td>70000</td>\n",
       "      <td>MyUkJobs</td>\n",
       "      <td>11.156265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                                 Title  \\\n",
       "138048  70437077                WEB & GRAPHIC DESIGNER   \n",
       "227554  72444591  Product Specialist  Facial  Midlands   \n",
       "10252   66314930            Commercial Lending Manager   \n",
       "\n",
       "                                          FullDescription  \\\n",
       "138048  These are exciting times, with new clients com...   \n",
       "227554  Product Specialist  Facial  Midlands Our clien...   \n",
       "10252   COMMERCIAL LENDING MANAGER This is an exciting...   \n",
       "\n",
       "                     LocationRaw LocationNormalized ContractType ContractTime  \\\n",
       "138048  Buckinghamshire, England    Buckinghamshire          NaN          NaN   \n",
       "227554             West Midlands      West Midlands          NaN    permanent   \n",
       "10252                    Cheadle            Cheadle          NaN          NaN   \n",
       "\n",
       "                         Company                          Category  \\\n",
       "138048                       NaN  PR, Advertising & Marketing Jobs   \n",
       "227554  Additional Resources Ltd                        Sales Jobs   \n",
       "10252            Blemain Finance         Accounting & Finance Jobs   \n",
       "\n",
       "                                        SalaryRaw  SalaryNormalized  \\\n",
       "138048         28000 - 30000 per annum + Benefits             29000   \n",
       "227554                            33000 Per Annum             33000   \n",
       "10252   up to 70,000 plus bonus, car and benefits             70000   \n",
       "\n",
       "                   SourceName  Log1pSalary  \n",
       "138048  onlymarketingjobs.com    10.275085  \n",
       "227554          totaljobs.com    10.404293  \n",
       "10252                MyUkJobs    11.156265  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "data[text_columns] = data[text_columns].fillna('NaN')\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing text data\n",
    "\n",
    "Just like last week, applying NLP to a problem begins from tokenization: splitting raw text into sequences of tokens (words, punctuation, etc).\n",
    "\n",
    "__Your task__ is to lowercase and tokenize all texts under `Title` and `FullDescription` columns. Store the tokenized data as a __space-separated__ string of tokens for performance reasons.\n",
    "\n",
    "It's okay to use nltk tokenizers. Assertions were designed for WordPunctTokenizer, slight deviations are okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text:\n",
      "2         Mathematical Modeller / Simulation Analyst / O...\n",
      "100002    A successful and high achieving specialist sch...\n",
      "200002    Web Designer  HTML, CSS, JavaScript, Photoshop...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw text:\")\n",
    "print(data[\"FullDescription\"][2::100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok(x):\n",
    "    return \" \".join(tokenizer.tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "# see task above\n",
    "FullDescription = map(tok, list(data[\"FullDescription\"]))\n",
    "Title = map(tok, list(data[\"Title\"]))\n",
    "data['FullDescription'] = list(FullDescription)\n",
    "data['Title'] = list(Title)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can assume that our text is a space-separated list of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all words are equally useful. Some of them are typos or rare words that are only present a few times. \n",
    "\n",
    "Let's count how many times is each word present in the data so that we can build a \"white list\" of known words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
    "# build a dictionary { token -> it's count }\n",
    "from collections import Counter\n",
    "FullDesc = map(lambda x: x.split(), list(data[\"FullDescription\"]))\n",
    "Tit = map(lambda y: y.split(), list(data[\"Title\"]))\n",
    "Total_tokens = list(FullDesc) + list(Tit)\n",
    "total_tok = []\n",
    "for i in Total_tokens:\n",
    "    total_tok.extend(i)\n",
    "    \n",
    "token_counts = Counter(total_tok)\n",
    "\n",
    "# hint: you may or may not want to use collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 202704\n",
      "('and', 2657388)\n",
      "('.', 2523216)\n",
      "(',', 2318606)\n",
      "('the', 2080994)\n",
      "('to', 2019884)\n",
      "...\n",
      "('improvemen', 1)\n",
      "('techniciancivil', 1)\n",
      "('mlnlycke', 1)\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see how many words are there for each count\n",
    "plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
    "plt.xlabel(\"Word counts\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filter tokens a list of all tokens that occur at least 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 10\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [k for (k,v) in token_counts.items() if v >= min_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 34158\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Vocabulary size:\", len(tokens))\n",
    "\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build an inverse token index: a dictionary from token(string) to it's index in `tokens` (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id = {}\n",
    "for i in range(len(tokens)):\n",
    "    token_to_id[tokens[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's use the vocabulary you've built to map text lines into neural network-digestible matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[10807 30161  2166     1     1]\n",
      " [15020  2844     1     1     1]\n",
      " [27645 10201    16 15215 10804]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's  encode the categirical data we have.\n",
    "\n",
    "As usual, we shall use one-hot encoding for simplicity. Kudos if you use more advanced encodings: tf-idf, pretrained w2v etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The deep learning part\n",
    "\n",
    "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
    "\n",
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  195814\n",
      "Validation size =  48954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(data, max_len=None, word_dropout=0):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_batch(data_train[:3], max_len=10)['Categorical']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture\n",
    "\n",
    "Our basic model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clearly doesn't fit into keras' __Sequential__ interface. To build such a network, one will have to use __[Keras Functional API](https://keras.io/models/model/)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=64):\n",
    "    \"\"\" Build a model that maps three data sources to a single linear output: predicted log1p(salary) \"\"\"\n",
    "    l_title = L.Input(shape=[None], name=\"Title\")\n",
    "    l_descr = L.Input(shape=[None], name=\"FullDescription\")\n",
    "    l_categ = L.Input(shape=(n_cat_features), name=\"Categorical\")\n",
    "    \n",
    "    title_emb = L.Embedding(input_dim = 341587, output_dim = 100)(l_title)\n",
    "    flatten_title = L.SimpleRNN(10)(title_emb)\n",
    "    desc_emb = L.Embedding(input_dim = 341587, output_dim = 100)(l_descr)\n",
    "    flatten_desc = L.SimpleRNN(20)(desc_emb)\n",
    "    Dense = L.Dense(100, activation = 'relu')(l_categ)\n",
    "    \n",
    "    \n",
    "    conc = L.Concatenate()([flatten_title, flatten_desc, Dense])\n",
    "    \n",
    "    output_layer = L.Dense(1)(conc)\n",
    "    # end of your code\n",
    "    \n",
    "    model = keras.models.Model(inputs=[l_title, l_descr, l_categ], outputs=[output_layer])\n",
    "    model.compile('adam', 'mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Title (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " FullDescription (InputLayer)   [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_45 (Embedding)       (None, None, 100)    34158700    ['Title[0][0]']                  \n",
      "                                                                                                  \n",
      " embedding_46 (Embedding)       (None, None, 100)    34158700    ['FullDescription[0][0]']        \n",
      "                                                                                                  \n",
      " Categorical (InputLayer)       [(None, 3768)]       0           []                               \n",
      "                                                                                                  \n",
      " simple_rnn (SimpleRNN)         (None, 10)           1110        ['embedding_45[0][0]']           \n",
      "                                                                                                  \n",
      " simple_rnn_1 (SimpleRNN)       (None, 20)           2420        ['embedding_46[0][0]']           \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 100)          376900      ['Categorical[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 130)          0           ['simple_rnn[0][0]',             \n",
      "                                                                  'simple_rnn_1[0][0]',           \n",
      "                                                                  'dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 1)            131         ['concatenate_17[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 68,697,961\n",
      "Trainable params: 68,697,961\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:639: UserWarning: Input dict contained keys ['Log1pSalary'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:639: UserWarning: Input dict contained keys ['Log1pSalary'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "dummy_pred = model.predict(make_batch(data_train[:100]))\n",
    "dummy_loss = model.train_on_batch(make_batch(data_train[:100]), data_train['Log1pSalary'][:100])[0]\n",
    "assert dummy_pred.shape == (100, 1)\n",
    "assert len(np.unique(dummy_pred)) > 20, \"model returns suspiciously few unique outputs. Check your initialization\"\n",
    "assert np.ndim(dummy_loss) == 0 and 0. <= dummy_loss <= 250., \"make sure you minimize MSE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and evaluation\n",
    "\n",
    "As usual, we gonna feed our model with random minibatches of data. \n",
    "\n",
    "As we train, we want to monitor not only loss function, which is computed in log-space, but also the actual error measured in dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            target = batch.pop(target_column)\n",
    "            yield batch, target\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "\n",
    "We can now fit our model the usual minibatch way. The interesting part is that we train on an infinite stream of minibatches, produced by `iterate_minibatches` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_12560\\158869515.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(iterate_minibatches(data_train, batch_size, cycle=True, word_dropout=0.05),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 140s 1s/step - loss: 40.1315 - mean_absolute_error: 5.5902 - val_loss: 0.9990 - val_mean_absolute_error: 0.8423\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 138s 1s/step - loss: 0.3840 - mean_absolute_error: 0.4950 - val_loss: 0.3002 - val_mean_absolute_error: 0.4398\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 155s 2s/step - loss: 0.2684 - mean_absolute_error: 0.4132 - val_loss: 0.2347 - val_mean_absolute_error: 0.3861\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 183s 2s/step - loss: 0.2175 - mean_absolute_error: 0.3701 - val_loss: 0.1957 - val_mean_absolute_error: 0.3500\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 175s 2s/step - loss: 0.1843 - mean_absolute_error: 0.3383 - val_loss: 0.1743 - val_mean_absolute_error: 0.3284\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 171s 2s/step - loss: 0.1715 - mean_absolute_error: 0.3253 - val_loss: 0.1632 - val_mean_absolute_error: 0.3168\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 170s 2s/step - loss: 0.1590 - mean_absolute_error: 0.3114 - val_loss: 0.1575 - val_mean_absolute_error: 0.3110\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 168s 2s/step - loss: 0.1567 - mean_absolute_error: 0.3080 - val_loss: 0.1549 - val_mean_absolute_error: 0.3079\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 164s 2s/step - loss: 0.1527 - mean_absolute_error: 0.3058 - val_loss: 0.1532 - val_mean_absolute_error: 0.3061\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 163s 2s/step - loss: 0.1519 - mean_absolute_error: 0.3037 - val_loss: 0.1524 - val_mean_absolute_error: 0.3050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258619f23a0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 10            # definitely too small\n",
    "steps_per_epoch = 100  # for full pass over data: (len(data_train) - 1) // batch_size + 1\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.fit_generator(iterate_minibatches(data_train, batch_size, cycle=True, word_dropout=0.05), \n",
    "                    epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "                    \n",
    "                    validation_data=iterate_minibatches(data_val, batch_size, cycle=True),\n",
    "                    validation_steps=data_val.shape[0] // batch_size\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 28ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 34ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 19ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 34ms/step\n",
      "8/8 [==============================] - 0s 28ms/step\n",
      "8/8 [==============================] - 0s 28ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 28ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 44ms/step\n",
      "8/8 [==============================] - 0s 37ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 28ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 17ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 33ms/step\n",
      "8/8 [==============================] - 0s 49ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 30ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 17ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 28ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 32ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 19ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 30ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 32ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 30ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 34ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 17ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 28ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 48ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 32ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 17ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 30ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 30ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 33ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 30ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 30ms/step\n",
      "8/8 [==============================] - 0s 32ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "8/8 [==============================] - 0s 17ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 43ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 18ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 30ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 32ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 19ms/step\n",
      "8/8 [==============================] - 0s 51ms/step\n",
      "8/8 [==============================] - 0s 19ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 32ms/step\n",
      "8/8 [==============================] - 0s 32ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 19ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 28ms/step\n",
      "8/8 [==============================] - 0s 19ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 18ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 43ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 28ms/step\n",
      "8/8 [==============================] - 0s 30ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 30ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "8/8 [==============================] - 0s 32ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 33ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 28ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 28ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 47ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 1s 65ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 32ms/step\n",
      "8/8 [==============================] - 0s 32ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 19ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "1/8 [==>...........................] - ETA: 0s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [93]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean absolute error: \u001b[39m\u001b[38;5;132;01m%.5f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (abs_error \u001b[38;5;241m/\u001b[39m num_samples))\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m squared_error, abs_error\n\u001b[1;32m---> 13\u001b[0m \u001b[43mprint_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m print_metrics(model, data_val, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [93]\u001b[0m, in \u001b[0;36mprint_metrics\u001b[1;34m(model, data, batch_size, name, **kw)\u001b[0m\n\u001b[0;32m      2\u001b[0m squared_error \u001b[38;5;241m=\u001b[39m abs_error \u001b[38;5;241m=\u001b[39m num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y \u001b[38;5;129;01min\u001b[39;00m iterate_minibatches(data, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m----> 4\u001b[0m     batch_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m     squared_error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39msquare(batch_pred \u001b[38;5;241m-\u001b[39m batch_y))\n\u001b[0;32m      6\u001b[0m     abs_error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mabs(batch_pred \u001b[38;5;241m-\u001b[39m batch_y))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2382\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2380\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   2381\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2382\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   2384\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    931\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    935\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def print_metrics(model, data, batch_size=batch_size, name=\"\", **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    for batch_x, batch_y in iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw):\n",
    "        batch_pred = model.predict(batch_x)[:, 0]\n",
    "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
    "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
    "        num_samples += len(batch_y)\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
    "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
    "    return squared_error, abs_error\n",
    "    \n",
    "print_metrics(model, data_train, name='Train')\n",
    "print_metrics(model, data_val, name='Val');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus part: explaining model predictions\n",
    "\n",
    "It's usually a good idea to understand how your model works before you let it make actual decisions. It's simple for linear models: just see which words learned positive or negative weights. However, its much harder for neural networks that learn complex nonlinear dependencies.\n",
    "\n",
    "There are, however, some ways to look inside the black box:\n",
    "* Seeing how model responds to input perturbations\n",
    "* Finding inputs that maximize/minimize activation of some chosen neurons (_read more [on distill.pub](https://distill.pub/2018/building-blocks/)_)\n",
    "* Building local linear approximations to your neural network: [article](https://arxiv.org/abs/1602.04938), [eli5 library](https://github.com/TeamHG-Memex/eli5/tree/master/eli5/formatters)\n",
    "\n",
    "Today we gonna try the first method just because it's the simplest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(model, sample, col_name='Title'):\n",
    "    \"\"\" Computes the effect each word had on model predictions \"\"\"\n",
    "    sample = dict(sample)\n",
    "    sample_col_tokens = [tokens[token_to_id.get(tok, 0)] for tok in sample[col_name].split()]\n",
    "    data_drop_one_token = pd.DataFrame([sample] * (len(sample_col_tokens) + 1))\n",
    "\n",
    "    for drop_i in range(len(sample_col_tokens)):\n",
    "        data_drop_one_token.loc[drop_i, col_name] = ' '.join(UNK if i == drop_i else tok\n",
    "                                                   for i, tok in enumerate(sample_col_tokens)) \n",
    "\n",
    "    *predictions_drop_one_token, baseline_pred = model.predict(make_batch(data_drop_one_token))[:, 0]\n",
    "    diffs = baseline_pred - predictions_drop_one_token\n",
    "    return list(zip(sample_col_tokens, diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display_html\n",
    "\n",
    "def draw_html(tokens_and_weights, cmap=plt.get_cmap(\"bwr\"), display=True,\n",
    "              token_template=\"\"\"<span style=\"background-color: {color_hex}\">{token}</span>\"\"\",\n",
    "              font_style=\"font-size:14px;\"\n",
    "             ):\n",
    "    \n",
    "    def get_color_hex(weight):\n",
    "        rgba = cmap(1. / (1 + np.exp(weight)), bytes=True)\n",
    "        return '#%02X%02X%02X' % rgba[:3]\n",
    "    \n",
    "    tokens_html = [\n",
    "        token_template.format(token=token, color_hex=get_color_hex(weight))\n",
    "        for token, weight in tokens_and_weights\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    raw_html = \"\"\"<p style=\"{}\">{}</p>\"\"\".format(font_style, ' '.join(tokens_html))\n",
    "    if display:\n",
    "        display_html(HTML(raw_html))\n",
    "        \n",
    "    return raw_html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 192ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:639: UserWarning: Input dict contained keys ['Log1pSalary'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:20px;\"><span style=\"background-color: #FF7E7E\">sales</span> <span style=\"background-color: #FF5151\">specialist</span> <span style=\"background-color: #FF4E4E\">iv</span> <span style=\"background-color: #FF3131\">access</span> <span style=\"background-color: #FF8282\">and</span> <span style=\"background-color: #FF5151\">infusion</span></p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:14px;\"><span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FFFEFE\">representative</span> <span style=\"background-color: #FFFEFE\">medical</span> <span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #FFFEFE\">an</span> <span style=\"background-color: #FFFEFE\">opportunity</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">work</span> <span style=\"background-color: #FFFEFE\">for</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">industry</span> <span style=\"background-color: #FFFEFE\">leading</span> <span style=\"background-color: #FFFEFE\">manufacturer</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #FFFEFE\">solutions</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">formally</span> <span style=\"background-color: #FFFEFE\">recognised</span> <span style=\"background-color: #FFFEFE\">as</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">number</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FFFEFE\">company</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">this</span> <span style=\"background-color: #FFFEFE\">market</span> <span style=\"background-color: #FFFEFE\">space</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">our</span> <span style=\"background-color: #FFFEFE\">client</span> <span style=\"background-color: #FFFEFE\">are</span> <span style=\"background-color: #FFFEFE\">an</span> <span style=\"background-color: #FFFEFE\">ethical</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">dynamic</span> <span style=\"background-color: #FFFEFE\">organisation</span> <span style=\"background-color: #FFFEFE\">absolutely</span> <span style=\"background-color: #FFFEFE\">committed</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">advancement</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFFEFE\">innovative</span> <span style=\"background-color: #FFFEFE\">technologies</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">job</span> <span style=\"background-color: #FFFEFE\">title</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FFFEFE\">specialist</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #FFFEFE\">selling</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFFEFE\">medication</span> <span style=\"background-color: #FFFEFE\">delivery</span> <span style=\"background-color: #FFFEFE\">solutions</span> <span style=\"background-color: #FFFEFE\">selling</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">teams</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">infection</span> <span style=\"background-color: #FFFEFE\">control</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">lead</span> <span style=\"background-color: #FFFEFE\">intensive</span> <span style=\"background-color: #FFFEFE\">care</span> <span style=\"background-color: #FFFEFE\">nurse</span> <span style=\"background-color: #FFFEFE\">specialists</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">ward</span> <span style=\"background-color: #FFFEFE\">managers</span> <span style=\"background-color: #FFFEFE\">territory</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFFEFE\">east</span> <span style=\"background-color: #FFFEFE\">midlands</span> <span style=\"background-color: #FFFEFE\">location</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFFEFE\">east</span> <span style=\"background-color: #FFFEFE\">midlands</span> <span style=\"background-color: #FFFEFE\">package</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFFEFE\">basic</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FFFEFE\">k</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FFFEFE\">k</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">uncapped</span> <span style=\"background-color: #FFFEFE\">bonus</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">addition</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">full</span> <span style=\"background-color: #FFFEFE\">corporate</span> <span style=\"background-color: #FFFEFE\">benefits</span> <span style=\"background-color: #FFFEFE\">company</span> <span style=\"background-color: #FFFEFE\">information</span> <span style=\"background-color: #FFFEFE\">hugely</span> <span style=\"background-color: #FFFEFE\">ethical</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">professional</span> <span style=\"background-color: #FFFEFE\">global</span> <span style=\"background-color: #FFFEFE\">organisation</span> <span style=\"background-color: #FFFEFE\">extremely</span> <span style=\"background-color: #FFFEFE\">well</span> <span style=\"background-color: #FFFEFE\">established</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">uk</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">market</span> <span style=\"background-color: #FFFEFE\">leader</span> <span style=\"background-color: #FFFEFE\">across</span> <span style=\"background-color: #FFFEFE\">all</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFFEFE\">their</span> <span style=\"background-color: #FFFEFE\">core</span> <span style=\"background-color: #FFFEFE\">business</span> <span style=\"background-color: #FFFEFE\">areas</span> <span style=\"background-color: #FFFEFE\">focus</span> <span style=\"background-color: #FFFEFE\">on</span> <span style=\"background-color: #FFFEFE\">providing</span> <span style=\"background-color: #FFFEFE\">cutting</span> <span style=\"background-color: #FFFEFE\">edge</span> <span style=\"background-color: #FFFEFE\">solutions</span> <span style=\"background-color: #FFFEFE\">along</span> <span style=\"background-color: #FFFEFE\">with</span> <span style=\"background-color: #FFFEFE\">outstanding</span> <span style=\"background-color: #FFFEFE\">service</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">support</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">business</span> <span style=\"background-color: #FFFEFE\">that</span> <span style=\"background-color: #FFFEFE\">retain</span> <span style=\"background-color: #FFFEFE\">talented</span> <span style=\"background-color: #FFFEFE\">personnel</span> <span style=\"background-color: #FFFEFE\">by</span> <span style=\"background-color: #FFFEFE\">offering</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">strong</span> <span style=\"background-color: #FFFEFE\">platform</span> <span style=\"background-color: #FFFEFE\">for</span> <span style=\"background-color: #FFFEFE\">career</span> <span style=\"background-color: #FFFEFE\">development</span> <span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FFFEFE\">specialist</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #FFFEFE\">you</span> <span style=\"background-color: #FFFEFE\">must</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFFEFE\">/</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">following</span> <span style=\"background-color: #FFFEFE\">at</span> <span style=\"background-color: #FFFEFE\">least</span> <span style=\"background-color: #FFFEFE\">2</span> <span style=\"background-color: #FFFEFE\">years</span> <span style=\"background-color: #FFFEFE\">medical</span> <span style=\"background-color: #FFFEFE\">device</span> <span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FFFEFE\">experience</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">candidates</span> <span style=\"background-color: #FFFEFE\">who</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFFEFE\">sold</span> <span style=\"background-color: #FFFEFE\">disposables</span> <span style=\"background-color: #FFFEFE\">/</span> <span style=\"background-color: #FFFEFE\">consumables</span> <span style=\"background-color: #FFFEFE\">or</span> <span style=\"background-color: #FFFEFE\">similar</span> <span style=\"background-color: #FFFEFE\">into</span> <span style=\"background-color: #FFFEFE\">hospitals</span> <span style=\"background-color: #FFFEFE\">would</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFFEFE\">particular</span> <span style=\"background-color: #FFFEFE\">interest</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">candidates</span> <span style=\"background-color: #FFFEFE\">must</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFFEFE\">sold</span> <span style=\"background-color: #FFFEFE\">into</span> <span style=\"background-color: #FFFEFE\">hospitals</span> <span style=\"background-color: #FFFEFE\">demonstrable</span> <span style=\"background-color: #FFFEFE\">performance</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">achievements</span> <span style=\"background-color: #FFFEFE\">so</span> <span style=\"background-color: #FFFEFE\">far</span> <span style=\"background-color: #FFFEFE\">personable</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">adaptable</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">willing</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">learn</span> <span style=\"background-color: #FFFEFE\">keen</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">eager</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">success</span> <span style=\"background-color: #FFFEFE\">candidates</span> <span style=\"background-color: #FFFEFE\">must</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">degree</span> <span style=\"background-color: #FFFEFE\">or</span> <span style=\"background-color: #FFFEFE\">at</span> <span style=\"background-color: #FFFEFE\">least</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">able</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">show</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">strong</span> <span style=\"background-color: #FFFEFE\">ability</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">learn</span> <span style=\"background-color: #FFFEFE\">role</span> <span style=\"background-color: #FFFEFE\">information</span> <span style=\"background-color: #FFFEFE\">managing</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">east</span> <span style=\"background-color: #FFFEFE\">midlands</span> <span style=\"background-color: #FFFEFE\">region</span> <span style=\"background-color: #FFFEFE\">selling</span> <span style=\"background-color: #FFFEFE\">across</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">company</span> <span style=\"background-color: #FFFEFE\">'</span> <span style=\"background-color: #FFFEFE\">s</span> <span style=\"background-color: #FFFEFE\">range</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #FFFEFE\">solutions</span> <span style=\"background-color: #FFFEFE\">portfolio</span> <span style=\"background-color: #FFFEFE\">selling</span> <span style=\"background-color: #FFFEFE\">into</span> <span style=\"background-color: #FFFEFE\">lead</span> <span style=\"background-color: #FFFEFE\">intensive</span> <span style=\"background-color: #FFFEFE\">care</span> <span style=\"background-color: #FFFEFE\">nurse</span> <span style=\"background-color: #FFFEFE\">specialists</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">ward</span> <span style=\"background-color: #FFFEFE\">managers</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">teams</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">infection</span> <span style=\"background-color: #FFFEFE\">control</span> <span style=\"background-color: #FFFEFE\">teams</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">procurement</span> <span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FFFEFE\">specialist</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #FFFEFE\">candidates</span> <span style=\"background-color: #FFFEFE\">must</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">eligible</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">work</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">live</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">uk</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">please</span> <span style=\"background-color: #FFFEFE\">contact</span> <span style=\"background-color: #FFFEFE\">allan</span> <span style=\"background-color: #FFFEFE\">waller</span> <span style=\"background-color: #FFFEFE\">on</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FFFEFE\">or</span> <span style=\"background-color: #FFFEFE\">please</span> <span style=\"background-color: #FFFEFE\">hit</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">apply</span> <span style=\"background-color: #FFFEFE\">button</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">this</span> <span style=\"background-color: #FFFEFE\">job</span> <span style=\"background-color: #FFFEFE\">was</span> <span style=\"background-color: #FFFEFE\">originally</span> <span style=\"background-color: #FFFEFE\">posted</span> <span style=\"background-color: #FFFEFE\">as</span> <span style=\"background-color: #FFFEFE\">www</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">salestarget</span> <span style=\"background-color: #FEFEFF\">.</span> <span style=\"background-color: #FFFEFE\">co</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">uk</span> <span style=\"background-color: #FFFEFE\">/</span> <span style=\"background-color: #FEFEFF\">jobseeking</span> <span style=\"background-color: #FEFEFF\">/</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #A8A8FF\">****</span></p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 36605\n",
    "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
    "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
    "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 186ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:639: UserWarning: Input dict contained keys ['Log1pSalary'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:20px;\"><span style=\"background-color: #FF2121\">cleaning</span> <span style=\"background-color: #FF3131\">operative</span></p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:14px;\"><span style=\"background-color: #FFFEFE\">12</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">5</span> <span style=\"background-color: #FFFEFE\">hours</span> <span style=\"background-color: #FFFEFE\">per</span> <span style=\"background-color: #FFFEFE\">week</span> <span style=\"background-color: #FFFEFE\">monday</span> <span style=\"background-color: #FFFEFE\">friday</span> <span style=\"background-color: #FFFEFE\">9am</span> <span style=\"background-color: #FFFEFE\">11</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">30am</span> <span style=\"background-color: #FFFEFE\">duties</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">include</span> <span style=\"background-color: #FFFEFE\">sweeping</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">mopping</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">vacuuming</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">buffing</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">cleaning</span> <span style=\"background-color: #FFFEFE\">staff</span> <span style=\"background-color: #FFFEFE\">toilets</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">rest</span> <span style=\"background-color: #FFFEFE\">room</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">must</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">able</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">read</span> <span style=\"background-color: #FFFEFE\">as</span> <span style=\"background-color: #FFFEFE\">they</span> <span style=\"background-color: #FFFEFE\">will</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">using</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #FFFEFE\">which</span> <span style=\"background-color: #FFFEFE\">need</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #FFFEFE\">as</span> <span style=\"background-color: #FFFEFE\">per</span> <span style=\"background-color: #FFFEFE\">instructions</span> <span style=\"background-color: #FFFEFE\">on</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FEFEFF\">containers</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">sucessfull</span> <span style=\"background-color: #FFFEFE\">applicants</span> <span style=\"background-color: #FFFEFE\">will</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">trained</span> <span style=\"background-color: #FEFEFF\">on</span> <span style=\"background-color: #FFFEFE\">all</span> <span style=\"background-color: #FEFEFF\">electrical</span> <span style=\"background-color: #FEFEFF\">appliances</span> <span style=\"background-color: #FEFEFF\">and</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #FFFCFC\">of</span> <span style=\"background-color: #FFEAEA\">cleaning</span> <span style=\"background-color: #FFCECE\">materials</span> <span style=\"background-color: #8A8AFF\">.</span></p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 12077\n",
    "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
    "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
    "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 120081\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Salary (gbp): 4755.4033\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:20px;\"><span style=\"background-color: #FF0C0C\">senior</span> <span style=\"background-color: #FF1616\">account</span> <span style=\"background-color: #FF2828\">manager</span></p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:14px;\"><span style=\"background-color: #FFFEFE\">senior</span> <span style=\"background-color: #FFFEFE\">account</span> <span style=\"background-color: #FFFEFE\">manager</span> <span style=\"background-color: #FFFEFE\">or</span> <span style=\"background-color: #FFFEFE\">strategic</span> <span style=\"background-color: #FFFEFE\">partnership</span> <span style=\"background-color: #FFFEFE\">manager</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FFFEFE\">full</span> <span style=\"background-color: #FFFEFE\">package</span> <span style=\"background-color: #FFFEFE\">reading</span> <span style=\"background-color: #FFFEFE\">i</span> <span style=\"background-color: #FFFEFE\">am</span> <span style=\"background-color: #FFFEFE\">delighted</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">confirm</span> <span style=\"background-color: #FFFEFE\">that</span> <span style=\"background-color: #FFFEFE\">i</span> <span style=\"background-color: #FFFEFE\">am</span> <span style=\"background-color: #FFFEFE\">recruiting</span> <span style=\"background-color: #FFFEFE\">for</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">national</span> <span style=\"background-color: #FFFEFE\">leader</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">financial</span> <span style=\"background-color: #FFFEFE\">services</span> <span style=\"background-color: #FFFEFE\">market</span> <span style=\"background-color: #FFFEFE\">who</span> <span style=\"background-color: #FFFEFE\">seeks</span> <span style=\"background-color: #FFFEFE\">an</span> <span style=\"background-color: #FFFEFE\">experienced</span> <span style=\"background-color: #FFFEFE\">account</span> <span style=\"background-color: #FFFEFE\">manager</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">work</span> <span style=\"background-color: #FFFEFE\">with</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">director</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFFEFE\">strategic</span> <span style=\"background-color: #FFFEFE\">partnerships</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">you</span> <span style=\"background-color: #FFFEFE\">will</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">working</span> <span style=\"background-color: #FFFEFE\">with</span> <span style=\"background-color: #FFFEFE\">blue</span> <span style=\"background-color: #FFFEFE\">chip</span> <span style=\"background-color: #FFFEFE\">clients</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">major</span> <span style=\"background-color: #FFFEFE\">uk</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">international</span> <span style=\"background-color: #FFFEFE\">brands</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">this</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">fanatic</span> <span style=\"background-color: #FFFEFE\">opportunity</span> <span style=\"background-color: #FFFEFE\">for</span> <span style=\"background-color: #FFFEFE\">an</span> <span style=\"background-color: #FFFEFE\">account</span> <span style=\"background-color: #FFFEFE\">manager</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">join</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">uk</span> <span style=\"background-color: #FFFEFE\">leader</span> <span style=\"background-color: #FFFEFE\">at</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">senior</span> <span style=\"background-color: #FFFEFE\">level</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">opportunity</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">progress</span> <span style=\"background-color: #FFFEFE\">your</span> <span style=\"background-color: #FFFEFE\">career</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">your</span> <span style=\"background-color: #FFFEFE\">role</span> <span style=\"background-color: #FFFEFE\">you</span> <span style=\"background-color: #FFFEFE\">will</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">tasked</span> <span style=\"background-color: #FFFEFE\">with</span> <span style=\"background-color: #FFFEFE\">supporting</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">director</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">managing</span> <span style=\"background-color: #FFFEFE\">high</span> <span style=\"background-color: #FFFEFE\">profile</span> <span style=\"background-color: #FFFEFE\">business</span> <span style=\"background-color: #FFFEFE\">relationships</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">meeting</span> <span style=\"background-color: #FFFEFE\">with</span> <span style=\"background-color: #FFFEFE\">clients</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">developing</span> <span style=\"background-color: #FFFEFE\">relationships</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">addition</span> <span style=\"background-color: #FFFEFE\">you</span> <span style=\"background-color: #FFFEFE\">will</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">responsibility</span> <span style=\"background-color: #FFFEFE\">for</span> <span style=\"background-color: #FFFEFE\">leading</span> <span style=\"background-color: #FFFEFE\">online</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">digital</span> <span style=\"background-color: #FFFEFE\">search</span> <span style=\"background-color: #FFFEFE\">campaigns</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">marketing</span> <span style=\"background-color: #FFFEFE\">activity</span> <span style=\"background-color: #FFFEFE\">therefore</span> <span style=\"background-color: #FFFEFE\">knowledge</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">this</span> <span style=\"background-color: #FFFEFE\">area</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">proven</span> <span style=\"background-color: #FFFEFE\">experience</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">preferred</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">apply</span> <span style=\"background-color: #FFFEFE\">for</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">role</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFFEFE\">senior</span> <span style=\"background-color: #FFFEFE\">account</span> <span style=\"background-color: #FFFEFE\">manager</span> <span style=\"background-color: #FFFEFE\">you</span> <span style=\"background-color: #FFFEFE\">will</span> <span style=\"background-color: #FFFEFE\">need</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">following</span> <span style=\"background-color: #FFFEFE\">skills</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFFEFE\">experience</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">financial</span> <span style=\"background-color: #FFFEFE\">services</span> <span style=\"background-color: #FFFEFE\">industry</span> <span style=\"background-color: #FFFEFE\">would</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">beneficial</span> <span style=\"background-color: #FFFEFE\">although</span> <span style=\"background-color: #FFFEFE\">experience</span> <span style=\"background-color: #FFFEFE\">from</span> <span style=\"background-color: #FFFEFE\">big</span> <span style=\"background-color: #FFFEFE\">brands</span> <span style=\"background-color: #FFFEFE\">would</span> <span style=\"background-color: #FFFEFE\">also</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">acceptable</span> <span style=\"background-color: #FFFEFE\">dealing</span> <span style=\"background-color: #FFFEFE\">with</span> <span style=\"background-color: #FFFEFE\">senior</span> <span style=\"background-color: #FFFEFE\">/</span> <span style=\"background-color: #FFFEFE\">director</span> <span style=\"background-color: #FFFEFE\">level</span> <span style=\"background-color: #FFFEFE\">relationships</span> <span style=\"background-color: #FFFEFE\">34</span> <span style=\"background-color: #FFFEFE\">years</span> <span style=\"background-color: #FFFEFE\">experience</span> <span style=\"background-color: #FFFEFE\">knowledge</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFFEFE\">online</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">digital</span> <span style=\"background-color: #FFFEFE\">search</span> <span style=\"background-color: #FFFEFE\">campaigns</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">marketing</span> <span style=\"background-color: #FFFEFE\">activity</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">preferred</span> <span style=\"background-color: #FFFEFE\">strong</span> <span style=\"background-color: #FFFEFE\">communication</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">interpersonal</span> <span style=\"background-color: #FFFEFE\">skills</span> <span style=\"background-color: #FFFEFE\">with</span> <span style=\"background-color: #FFFEFE\">excellent</span> <span style=\"background-color: #FFFEFE\">gravitas</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">return</span> <span style=\"background-color: #FFFEFE\">you</span> <span style=\"background-color: #FFFEFE\">will</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">joining</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">recognised</span> <span style=\"background-color: #FFFEFE\">brand</span> <span style=\"background-color: #FFFEFE\">that</span> <span style=\"background-color: #FFFEFE\">offers</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">sociable</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">friendly</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">professional</span> <span style=\"background-color: #FFFEFE\">working</span> <span style=\"background-color: #FFFEFE\">environment</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">who</span> <span style=\"background-color: #FFFEFE\">as</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">business</span> <span style=\"background-color: #FFFEFE\">get</span> <span style=\"background-color: #FFFEFE\">involved</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">charitable</span> <span style=\"background-color: #FFFEFE\">events</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">run</span> <span style=\"background-color: #FFFEFE\">monthly</span> <span style=\"background-color: #FFFEFE\">social</span> <span style=\"background-color: #FFFEFE\">events</span> <span style=\"background-color: #FFFEFE\">for</span> <span style=\"background-color: #FFFEFE\">employers</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">please</span> <span style=\"background-color: #FFFEFE\">attach</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FFFEFE\">references</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">your</span> <span style=\"background-color: #FFFEFE\">cv</span> <span style=\"background-color: #FFFEFE\">should</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">submitted</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">word</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">if</span> <span style=\"background-color: #FFFEFE\">you</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFFEFE\">any</span> <span style=\"background-color: #FFFEFE\">questions</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">please</span> <span style=\"background-color: #FFFEFE\">do</span> <span style=\"background-color: #FFFEFE\">not</span> <span style=\"background-color: #FFFEFE\">hesitate</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">contact</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #FEFEFF\">on</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FEFEFF\">****</span> <span style=\"background-color: #FEFEFF\">****</span> <span style=\"background-color: #FEFEFF\">or</span> <span style=\"background-color: #FEFEFF\">email</span> <span style=\"background-color: #FEFEFF\">click</span> <span style=\"background-color: #FFFEFE\">here</span> <span style=\"background-color: #FFFCFC\">to</span> <span style=\"background-color: #FFEAEA\">contact</span> <span style=\"background-color: #FFCCCC\">this</span> <span style=\"background-color: #FF8383\">recruiter</span></p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(len(data))\n",
    "print(\"Index:\", i)\n",
    "print(\"Salary (gbp):\", np.expm1(model.predict(make_batch(data.iloc[i: i+1]))[0, 0]))\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
    "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
    "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Terrible start-up idea #1962:__ make a tool that automaticaly rephrases your job description (or CV) to meet salary expectations :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final task: improve over it\n",
    "\n",
    "Your main task is to use some of the tricks you've learned on the network and analyze if you can improve __validation MAE__. Try __at least 3 options__ from the list below for a full grade. Write a short report about what you have tried. More ideas = more bonus points. \n",
    "\n",
    "__Please be serious:__ \" plot learning curves in MAE/epoch, compare models based on optimal performance, test one change at a time. You know this stuff.\n",
    "\n",
    "#### A) CNN architecture\n",
    "\n",
    "All the tricks you know about dense and convolutional neural networks apply here as well.\n",
    "* Dropout. \n",
    "* Batch Norm. \n",
    "* Parallel convolution layers. The idea is that you apply several nn.Conv1d to the same embeddings and concatenate output channels.\n",
    "* More layers, more neurons \n",
    "\n",
    "\n",
    "#### B) Play with pooling\n",
    "\n",
    "There's more than one way to perform pooling:\n",
    "* Max over time - our `L.GlobalMaxPool1D`\n",
    "* Average over time (excluding PAD)\n",
    "* Softmax-pooling:\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot {{e ^ {h_{i, t}}} \\over \\sum_\\tau e ^ {h_{j, \\tau}} } }$$\n",
    "\n",
    "* Attentive pooling\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot Attn(h_t)}$$\n",
    "\n",
    ", where $$ Attn(h_t) = {{e ^ {NN_{attn}(h_t)}} \\over \\sum_\\tau e ^ {NN_{attn}(h_\\tau)}}  $$\n",
    "and $NN_{attn}$ is a dense layer.\n",
    "\n",
    "The optimal score is usually achieved by concatenating several different poolings, including several attentive pooling with different $NN_{attn}$ (aka multi-headed attention).\n",
    "\n",
    "The catch is that keras layers do not inlude those toys. You will have to [write your own keras layer](https://keras.io/layers/writing-your-own-keras-layers/).\n",
    "\n",
    "#### C) Fun with words\n",
    "\n",
    "It's not always a good idea to train embeddings from scratch. Here's a few tricks:\n",
    "\n",
    "* Use a pre-trained embeddings from `gensim.downloader.load`. See last lecture.\n",
    "* Start with pre-trained embeddings, then fine-tune them with gradient descent. You may or may not want to use __`.get_keras_embedding()`__ method for word2vec\n",
    "* Use the same embedding matrix in title and desc vectorizer\n",
    "\n",
    "\n",
    "#### D) Going recurrent\n",
    "\n",
    "We've already learned that recurrent networks can do cool stuff in sequence modelling. Turns out, they're not useless for classification as well. With some tricks of course..\n",
    "\n",
    "* Like convolutional layers, LSTM should be pooled into a fixed-size vector with some of the poolings.\n",
    "* Since you know all the text in advance, use bidirectional RNN\n",
    "  * Run one LSTM from left to right\n",
    "  * Run another in parallel from right to left \n",
    "  * Concatenate their output sequences along unit axis (dim=-1)\n",
    "\n",
    "* It might be good idea to mix convolutions and recurrent layers differently for title and description\n",
    "\n",
    "\n",
    "#### E) Optimizing seriously\n",
    "\n",
    "* You don't necessarily need 100 epochs. Use early stopping. If you've never done this before, take a look at [early stopping callback](https://keras.io/api/callbacks/early_stopping/).\n",
    "  * In short, train until you notice that validation\n",
    "  * Maintain the best-on-validation snapshot via `model.save(file_name)`\n",
    "  * Plotting learning curves is usually a good idea\n",
    "  \n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
