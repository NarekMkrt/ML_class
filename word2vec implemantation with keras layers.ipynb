{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0688f7b0",
   "metadata": {
    "id": "0688f7b0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Dot, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ade94ad9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "ade94ad9",
    "outputId": "43030845-f352-489d-ed6a-15e28e592c1b"
   },
   "outputs": [],
   "source": [
    "with open('corpus_100k', 'r', encoding = 'utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4972ab38",
   "metadata": {
    "id": "4972ab38"
   },
   "outputs": [],
   "source": [
    "#Creating word_bag and choosing 300,000 of them, because the RAM couldn't handle\n",
    "text.lower()\n",
    "word_bag = text.split()[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "CSkKhqWZIimu",
   "metadata": {
    "id": "CSkKhqWZIimu"
   },
   "outputs": [],
   "source": [
    "uniques, freq = np.unique(word_bag, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ef48f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(word_bag)):\n",
    "    empty = [0]*len(uniques)\n",
    "    empty[list(uniques).index(word_bag[i])] = 1\n",
    "    word_bag[i] = empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c800020",
   "metadata": {
    "id": "0c800020"
   },
   "outputs": [],
   "source": [
    "# This function creates (input, target) word couples, with the window_size\n",
    "def word_pairs(word_list, window_size):\n",
    "    word_pairs = []\n",
    "    for i in range(window_size, len(word_list)-window_size):\n",
    "        for j in range(1,window_size+1):\n",
    "            word_pairs.append((word_list[i],word_list[i-j]))\n",
    "            word_pairs.append((word_list[i],word_list[i+j]))\n",
    "\n",
    "    return word_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a5050b5",
   "metadata": {
    "id": "2a5050b5"
   },
   "outputs": [],
   "source": [
    "word_pair = word_pairs(word_bag,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ei3zhyitdT5e",
   "metadata": {
    "id": "ei3zhyitdT5e"
   },
   "outputs": [],
   "source": [
    "#distribution of words with frequencies\n",
    "def distribution(word_bag, uniques, freq):\n",
    "  word_freq = {word: frequency/len(word_bag) for word, frequency in zip(uniques, freq)}\n",
    "\n",
    "  return np.array([word_freq[word] for word in uniques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sJnj1ILNYi1M",
   "metadata": {
    "id": "sJnj1ILNYi1M"
   },
   "outputs": [],
   "source": [
    "#Randomly choose negative targets.\n",
    "def negative_sampling(n_negative, word_bag, uniques, freq):\n",
    "  negative_targets = []\n",
    "  dist = distribution(word_bag, uniques, freq)\n",
    "  for n in range(n_negative):\n",
    "    target = [0] * len(uniques)\n",
    "    indx = np.random.choice(range(len(uniques)), p=dist)\n",
    "    target[indx] = 1\n",
    "    negative_targets.append(target)\n",
    "\n",
    "  return negative_targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "NtbXQ611xrLl",
   "metadata": {
    "id": "NtbXQ611xrLl"
   },
   "outputs": [],
   "source": [
    "def train_data_generator(word_pair, batch_size, uniques, freq):\n",
    "  while True:\n",
    "    batch_word_pairs = random.sample(word_pair, batch_size)\n",
    "    input_words, target_words, labels = [], [], []\n",
    "\n",
    "    for context_word, target_word in batch_word_pairs:\n",
    "      input_words.append(context_word)\n",
    "      target_words.append(target_word)\n",
    "      labels.append(1)\n",
    "\n",
    "      negative_samples = negative_sampling(20, word_bag, uniques, freq)\n",
    "      for negative_word in negative_samples:\n",
    "        input_words.append(context_word)\n",
    "        target_words.append(negative_word)\n",
    "        labels.append(0)\n",
    "\n",
    "    X_target = np.array(target_words)\n",
    "    X_context = np.array(input_words)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    yield ([X_context, X_target], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "LQeVhB3HmRJk",
   "metadata": {
    "id": "LQeVhB3HmRJk"
   },
   "outputs": [],
   "source": [
    "inp = tf.keras.Input(shape = (1,))\n",
    "target = tf.keras.Input(shape = (1,))\n",
    "input_embedding = Embedding(input_dim=len(uniques), output_dim=300)(inp)\n",
    "target_embedding = Embedding(input_dim=len(uniques), output_dim=300)(target)\n",
    "\n",
    "\n",
    "dot_product = Dot(axes=-1)([input_embedding, target_embedding])\n",
    "\n",
    "\n",
    "flat_output = Flatten()(dot_product)\n",
    "model = tf.keras.Model(inputs=[inp, target], outputs=flat_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "QDTOpNJgvqXt",
   "metadata": {
    "id": "QDTOpNJgvqXt"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "RBgnFD4UtlDI",
   "metadata": {
    "id": "RBgnFD4UtlDI"
   },
   "outputs": [],
   "source": [
    "data = train_data_generator(word_pair, 1, uniques, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "kZ6fShZQt2DV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "kZ6fShZQt2DV",
    "outputId": "d4887bcb-d947-4303-f54b-10898a644c71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'binary_crossentropy/clip_by_value' defined at (most recent call last):\n    File \"C:\\Users\\danie\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\danie\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\danie\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\danie\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\danie\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_15300\\2443799714.py\", line 1, in <cell line: 1>\n      model.fit(data, epochs=10, steps_per_epoch=len(word_pair)//16)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2156, in binary_crossentropy\n      backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5712, in binary_crossentropy\n      output = tf.clip_by_value(output, epsilon_, 1.0 - epsilon_)\nNode: 'binary_crossentropy/clip_by_value'\nOOM when allocating tensor with shape[336,10144225] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node binary_crossentropy/clip_by_value}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1597]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mword_pair\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'binary_crossentropy/clip_by_value' defined at (most recent call last):\n    File \"C:\\Users\\danie\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\danie\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\danie\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\danie\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\danie\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_15300\\2443799714.py\", line 1, in <cell line: 1>\n      model.fit(data, epochs=10, steps_per_epoch=len(word_pair)//16)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2156, in binary_crossentropy\n      backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5712, in binary_crossentropy\n      output = tf.clip_by_value(output, epsilon_, 1.0 - epsilon_)\nNode: 'binary_crossentropy/clip_by_value'\nOOM when allocating tensor with shape[336,10144225] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node binary_crossentropy/clip_by_value}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1597]"
     ]
    }
   ],
   "source": [
    "model.fit(data, epochs=10, steps_per_epoch=len(word_pair))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
