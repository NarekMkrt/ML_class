{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972d1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e518234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Constantinople.txt\", encoding=\"utf8\") as data:\n",
    "    text = data.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982b5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61a46a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_char = [0]*len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbffe46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_data = [text[i] for i in range(0,len(text)-1)]\n",
    "Labels = [text[i] for i in range(1,len(text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849bd059",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_vecs = []\n",
    "labels_vecs = []\n",
    "zero_char = [0]*len(chars)\n",
    "for i in range(len(Input_data)):\n",
    "    idx = chars.index(Input_data[i])\n",
    "    x = zero_char.copy()\n",
    "    x[idx] = 1\n",
    "    input_data_vecs.append(x)\n",
    "labels_vecs = []\n",
    "for i in range(len(Labels)):\n",
    "    idx = chars.index(Labels[i])\n",
    "    y = zero_char.copy()\n",
    "    y[idx] = 1\n",
    "    labels_vecs.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d07488",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array(input_data_vecs)\n",
    "labels = np.array(labels_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c39af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vanilla_RNN:\n",
    "    def __init__(self, learning_rate = 0.0005, n_epochs = 20, sequence_length = 20):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_epochs = n_epochs\n",
    "        self.sequence_length = sequence_length\n",
    "        self.W = None\n",
    "        self.U = None\n",
    "        self.V = None\n",
    "        self.b = None\n",
    "        self.c = None\n",
    "\n",
    "    def loss(self, y_pred, y):\n",
    "        return -np.sum(y*np.log(y_pred))\n",
    "\n",
    "\n",
    "    def fit(self, inputs, outputs, size):\n",
    "        self.W = np.random.randn(size, inputs.shape[1])\n",
    "        self.U = np.random.randn(size, size)\n",
    "        self.V = np.random.randn(inputs.shape[1], size)\n",
    "        self.b = np.zeros((size, 1))\n",
    "        self.c = np.zeros((inputs.shape[1], 1))\n",
    "\n",
    "        #it is like making batches\n",
    "        inputs_fin = []\n",
    "        for i in range(0,inputs.shape[0], self.sequence_length):\n",
    "            inputs_fin.append(inputs[i:i+self.sequence_length])\n",
    "        outputs_fin = []\n",
    "        for i in range(0,outputs.shape[0], self.sequence_length):\n",
    "            outputs_fin.append(outputs[i:i+self.sequence_length])\n",
    "        \n",
    "        #iterating n_epochs time\n",
    "        for n in range(self.n_epochs):\n",
    "\n",
    "            #iterating batches\n",
    "            for k in range(len(inputs_fin)):\n",
    "                h_prev = np.zeros((size, 1))\n",
    "                h = []\n",
    "                y_probs = []\n",
    "                loss_list = []\n",
    "                for t in range(self.sequence_length):\n",
    "                    h_prev = np.tanh(np.dot(self.U,h_prev) + np.dot(self.W, np.array(inputs_fin[k][t]).reshape(inputs.shape[1],1)) + self.b)\n",
    "                    h.append(h_prev)\n",
    "                    o_t = np.dot(self.V, h_prev) + self.c\n",
    "                    y_t = np.exp(o_t)/np.sum(np.exp(o_t))\n",
    "                    y_probs.append(y_t)\n",
    "                    loss_list.append(self.loss(y_t, outputs_fin[k][t]))\n",
    "                    \n",
    "                L = np.sum(loss_list)\n",
    "                #back_prop\n",
    "                dV = np.zeros_like(self.V)\n",
    "                dU = np.zeros_like(self.U)\n",
    "                dW = np.zeros_like(self.W)\n",
    "                db = np.zeros_like(self.b)\n",
    "                dc = np.zeros_like(self.c)\n",
    "\n",
    "                for t in reversed(range(self.sequence_length)):\n",
    "                    dy = (np.array(y_probs[t]) - np.array(outputs_fin[k][t]).reshape(inputs.shape[1],1))\n",
    "                    dV += dy @ h[t].T\n",
    "                    dc += dy\n",
    "                        \n",
    "                    grad = (self.V.T @ dy) * (1-h[t]**2)\n",
    "                    dW += grad @ np.array(inputs_fin[k][t]).reshape(inputs.shape[1],1).T\n",
    "                    dU += grad @ h[t-1].T if t > 0 else np.zeros_like(self.U)\n",
    "                    db += grad\n",
    "\n",
    "                #updating_params\n",
    "                self.W -= self.learning_rate * dW\n",
    "                self.U -= self.learning_rate * dU\n",
    "                self.V -= self.learning_rate * dV\n",
    "                self.b -= self.learning_rate * db\n",
    "                self.c -= self.learning_rate * dc\n",
    "\n",
    "            print('# of epoch is',n+1,'   total loss is', L)\n",
    "\n",
    "    def predict(self, input_text_array):\n",
    "        h_prev = np.zeros_like(self.b)\n",
    "        ys = []\n",
    "        for t in range(self.sequence_length):\n",
    "            y = np.zeros((input_text_array.shape[1],1))\n",
    "            try:\n",
    "                h_prev = np.tanh(np.dot(self.U,h_prev) + np.dot(self.W, np.array(input_text_array[t]).reshape(input_text_array.shape[1],1)) + self.b)\n",
    "            except:\n",
    "                h_prev = np.tanh(np.dot(self.U,h_prev) + np.dot(self.W, ys[t-1]) + self.b)\n",
    "            o_t = np.dot(self.V, h_prev) + self.c\n",
    "            y_t = np.exp(o_t)/np.sum(np.exp(o_t))\n",
    "            indx = np.argmax(y_t)\n",
    "            y[indx] = 1\n",
    "            ys.append(y)\n",
    "\n",
    "        return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edd48c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epoch is 1    total loss is 21399.520021164433\n",
      "# of epoch is 2    total loss is 16033.071594276416\n",
      "# of epoch is 3    total loss is 15205.59341769396\n",
      "# of epoch is 4    total loss is 14738.563737748576\n",
      "# of epoch is 5    total loss is 14396.907170285154\n",
      "# of epoch is 6    total loss is 14055.451280241909\n",
      "# of epoch is 7    total loss is 13775.431134920558\n",
      "# of epoch is 8    total loss is 13561.842986663447\n",
      "# of epoch is 9    total loss is 13380.88473414147\n",
      "# of epoch is 10    total loss is 13207.360826641396\n",
      "# of epoch is 11    total loss is 13130.125315824263\n",
      "# of epoch is 12    total loss is 13101.018563551672\n",
      "# of epoch is 13    total loss is 13068.303746881174\n",
      "# of epoch is 14    total loss is 13034.450197340431\n",
      "# of epoch is 15    total loss is 12999.598686292267\n",
      "# of epoch is 16    total loss is 12956.863415703361\n",
      "# of epoch is 17    total loss is 12916.282831300427\n",
      "# of epoch is 18    total loss is 12881.893846835643\n",
      "# of epoch is 19    total loss is 12855.31695859144\n",
      "# of epoch is 20    total loss is 12836.190326446373\n"
     ]
    }
   ],
   "source": [
    "rnn = Vanilla_RNN()\n",
    "rnn.fit(inputs, labels,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f709dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'what'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fb2256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v= []\n",
    "for i in range(len(text)):\n",
    "    idx = chars.index(text[i])\n",
    "    x = zero_char.copy()\n",
    "    x[idx] = 1\n",
    "    v.append(x)\n",
    "    \n",
    "test_text = np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c368a8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd5d7783",
   "metadata": {},
   "outputs": [],
   "source": [
    "jh = rnn.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fe72464",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = text\n",
    "for i in range(len(text),len(jh)):\n",
    "    new_text+=chars[np.argmax(jh[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1e3237b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whatan the the the t'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea86ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't predicts well after all :))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
